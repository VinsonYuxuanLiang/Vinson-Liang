{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e97348a",
   "metadata": {},
   "source": [
    "# Project Assignment 1#\n",
    "By: Qingwen Jia, Jiale Qian,Vinson Liang, Joses Ng, Natalie Choy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e0bd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_indicators = pd.read_csv('country_indicators.csv')\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "df_preds = pd.read_csv('test_predictions.csv')\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3264294",
   "metadata": {},
   "source": [
    "# 1. Create the Prediciton Probability \"Error\" results for the xgboost and ffnn models analagously to the transformer model produced above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a98d0014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_ffnn</th>\n",
       "      <th>y_pred_proba_ffnn</th>\n",
       "      <th>ffnn_probability_prediction_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.409958</td>\n",
       "      <td>0.409958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0.406696</td>\n",
       "      <td>0.406696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0.545236</td>\n",
       "      <td>0.545236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0.534560</td>\n",
       "      <td>0.534560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>0.538583</td>\n",
       "      <td>0.461417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>False</td>\n",
       "      <td>0.291874</td>\n",
       "      <td>0.291874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>False</td>\n",
       "      <td>0.300321</td>\n",
       "      <td>0.300321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>False</td>\n",
       "      <td>0.335496</td>\n",
       "      <td>0.335496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>False</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>0.324000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>True</td>\n",
       "      <td>0.332455</td>\n",
       "      <td>0.667545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_true_ffnn  y_pred_proba_ffnn  ffnn_probability_prediction_error\n",
       "0          False           0.409958                           0.409958\n",
       "1          False           0.406696                           0.406696\n",
       "2          False           0.545236                           0.545236\n",
       "3          False           0.534560                           0.534560\n",
       "4           True           0.538583                           0.461417\n",
       "..           ...                ...                                ...\n",
       "359        False           0.291874                           0.291874\n",
       "360        False           0.300321                           0.300321\n",
       "361        False           0.335496                           0.335496\n",
       "362        False           0.324000                           0.324000\n",
       "363         True           0.332455                           0.667545\n",
       "\n",
       "[364 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds['ffnn_probability_prediction_error'] = np.abs(df_preds['y_true_ffnn'].astype(float) - df_preds['y_pred_proba_ffnn'])\n",
    "df_preds[['y_true_ffnn','y_pred_proba_ffnn','ffnn_probability_prediction_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e7eab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_proba_xgboost</th>\n",
       "      <th>xgboost_probability_prediction_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.066500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0.099643</td>\n",
       "      <td>0.099643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0.704086</td>\n",
       "      <td>0.295914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>0.638444</td>\n",
       "      <td>0.361556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0.608380</td>\n",
       "      <td>0.608380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>False</td>\n",
       "      <td>0.079453</td>\n",
       "      <td>0.079453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>False</td>\n",
       "      <td>0.060189</td>\n",
       "      <td>0.060189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>True</td>\n",
       "      <td>0.697625</td>\n",
       "      <td>0.302375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>False</td>\n",
       "      <td>0.729246</td>\n",
       "      <td>0.729246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>False</td>\n",
       "      <td>0.591722</td>\n",
       "      <td>0.591722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_true_xgboost  y_pred_proba_xgboost  \\\n",
       "0             False              0.066500   \n",
       "1             False              0.099643   \n",
       "2              True              0.704086   \n",
       "3              True              0.638444   \n",
       "4             False              0.608380   \n",
       "..              ...                   ...   \n",
       "359           False              0.079453   \n",
       "360           False              0.060189   \n",
       "361            True              0.697625   \n",
       "362           False              0.729246   \n",
       "363           False              0.591722   \n",
       "\n",
       "     xgboost_probability_prediction_error  \n",
       "0                                0.066500  \n",
       "1                                0.099643  \n",
       "2                                0.295914  \n",
       "3                                0.361556  \n",
       "4                                0.608380  \n",
       "..                                    ...  \n",
       "359                              0.079453  \n",
       "360                              0.060189  \n",
       "361                              0.302375  \n",
       "362                              0.729246  \n",
       "363                              0.591722  \n",
       "\n",
       "[364 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds['xgboost_probability_prediction_error'] = np.abs(df_preds['y_true_xgboost'].astype(float) - df_preds['y_pred_proba_xgboost'])\n",
    "df_preds[['y_true_xgboost','y_pred_proba_xgboost','xgboost_probability_prediction_error']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d071dc3",
   "metadata": {},
   "source": [
    "# 2. Create a bootsrap confidence interval for the average Prediction Probability \"Error\" for one of these models using all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa040633",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 364\n",
    "repetitions = 10000\n",
    "my_bootstrapped_population_sample_means = np.zeros(repetitions)\n",
    "for i in range(repetitions):\n",
    "    my_bootstrapped_population_sample_n364 = \\\n",
    "        np.random.choice(df_preds['xgboost_probability_prediction_error'], size=364, replace=True)\n",
    "    my_bootstrapped_population_sample_means[i] = \\\n",
    "        my_bootstrapped_population_sample_n364.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32cb8b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42609405, 0.46481134])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#95% Confidence Interval\n",
    "np.quantile(my_bootstrapped_population_sample_means, [0.05, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a79d83",
   "metadata": {},
   "source": [
    "# 3. Create the Prediction Classification \"Correctness\" results of \"correct\" and \"incorrect\" predictions for the transformer, xgboost and ffnn models; or, an alternative \"either/or\" breakdown of interest (such as \"wrongly predicted no escalation\" versus all the other categories combined)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f596b037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_transformer</th>\n",
       "      <th>transformer_classifcation_performance_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_true_transformer  y_pred_transformer  \\\n",
       "30                True                True   \n",
       "31               False                True   \n",
       "32               False                True   \n",
       "33               False                True   \n",
       "34               False               False   \n",
       "35               False                True   \n",
       "36               False               False   \n",
       "37               False               False   \n",
       "38               False                True   \n",
       "39               False                True   \n",
       "40               False                True   \n",
       "41               False                True   \n",
       "42               False                True   \n",
       "43               False               False   \n",
       "44               False               False   \n",
       "45               False               False   \n",
       "46               False               False   \n",
       "47                True               False   \n",
       "48               False               False   \n",
       "49               False               False   \n",
       "\n",
       "   transformer_classifcation_performance_outcome  \n",
       "30                correctly predicted escalation  \n",
       "31                  wrongly predicted escalation  \n",
       "32                  wrongly predicted escalation  \n",
       "33                  wrongly predicted escalation  \n",
       "34             correctly predicted no escalation  \n",
       "35                  wrongly predicted escalation  \n",
       "36             correctly predicted no escalation  \n",
       "37             correctly predicted no escalation  \n",
       "38                  wrongly predicted escalation  \n",
       "39                  wrongly predicted escalation  \n",
       "40                  wrongly predicted escalation  \n",
       "41                  wrongly predicted escalation  \n",
       "42                  wrongly predicted escalation  \n",
       "43             correctly predicted no escalation  \n",
       "44             correctly predicted no escalation  \n",
       "45             correctly predicted no escalation  \n",
       "46             correctly predicted no escalation  \n",
       "47               wrongly predicted no escalation  \n",
       "48             correctly predicted no escalation  \n",
       "49             correctly predicted no escalation  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformer\n",
    "threshold = 0.5\n",
    "df_preds['transformer_classifcation_performance_outcome'] = None\n",
    "\n",
    "tmp = df_preds['transformer_classifcation_performance_outcome'].copy()\n",
    "TP_pos_pred_correct = df_preds.y_true_transformer & (df_preds.y_pred_proba_transformer>threshold)\n",
    "tmp[TP_pos_pred_correct] = \"correctly predicted escalation\"\n",
    "TN_neg_pred_correct = (~df_preds.y_true_transformer) & (df_preds.y_pred_proba_transformer<=threshold)\n",
    "tmp[TN_neg_pred_correct] = \"correctly predicted no escalation\"\n",
    "FP_pos_pred_wrong = (~df_preds.y_true_transformer) & (df_preds.y_pred_proba_transformer>threshold)\n",
    "tmp[FP_pos_pred_wrong] = \"wrongly predicted escalation\"\n",
    "FN_neg_pred_wrong = df_preds.y_true_transformer & (df_preds.y_pred_proba_transformer<=threshold)\n",
    "tmp[FN_neg_pred_wrong] = \"wrongly predicted no escalation\"\n",
    "\n",
    "df_preds['transformer_classifcation_performance_outcome'] = tmp\n",
    "df_preds[['y_true_transformer','y_pred_transformer','transformer_classifcation_performance_outcome']][30:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a167ff2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_xgboost</th>\n",
       "      <th>xgboost_classifcation_performance_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_true_xgboost  y_pred_xgboost xgboost_classifcation_performance_outcome\n",
       "30           False            True              wrongly predicted escalation\n",
       "31           False            True              wrongly predicted escalation\n",
       "32           False            True              wrongly predicted escalation\n",
       "33           False            True              wrongly predicted escalation\n",
       "34           False           False         correctly predicted no escalation\n",
       "35           False            True              wrongly predicted escalation\n",
       "36           False            True              wrongly predicted escalation\n",
       "37           False            True              wrongly predicted escalation\n",
       "38            True            True            correctly predicted escalation\n",
       "39           False            True              wrongly predicted escalation\n",
       "40           False            True              wrongly predicted escalation\n",
       "41            True            True            correctly predicted escalation\n",
       "42           False            True              wrongly predicted escalation\n",
       "43           False            True              wrongly predicted escalation\n",
       "44           False            True              wrongly predicted escalation\n",
       "45            True            True            correctly predicted escalation\n",
       "46            True           False           wrongly predicted no escalation\n",
       "47           False            True              wrongly predicted escalation\n",
       "48            True            True            correctly predicted escalation\n",
       "49           False            True              wrongly predicted escalation"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgboost\n",
    "threshold = 0.5\n",
    "df_preds['xgboost_classifcation_performance_outcome'] = None\n",
    "\n",
    "tmp = df_preds['xgboost_classifcation_performance_outcome'].copy()\n",
    "TP_pos_pred_correct = df_preds.y_true_xgboost & (df_preds.y_pred_proba_xgboost>threshold)\n",
    "tmp[TP_pos_pred_correct] = \"correctly predicted escalation\"\n",
    "TN_neg_pred_correct = (~df_preds.y_true_xgboost) & (df_preds.y_pred_proba_xgboost<=threshold)\n",
    "tmp[TN_neg_pred_correct] = \"correctly predicted no escalation\"\n",
    "FP_pos_pred_wrong = (~df_preds.y_true_xgboost) & (df_preds.y_pred_proba_xgboost>threshold)\n",
    "tmp[FP_pos_pred_wrong] = \"wrongly predicted escalation\"\n",
    "FN_neg_pred_wrong = df_preds.y_true_xgboost & (df_preds.y_pred_proba_xgboost<=threshold)\n",
    "tmp[FN_neg_pred_wrong] = \"wrongly predicted no escalation\"\n",
    "\n",
    "df_preds['xgboost_classifcation_performance_outcome'] = tmp\n",
    "df_preds[['y_true_xgboost','y_pred_xgboost','xgboost_classifcation_performance_outcome']][30:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b353edb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_ffnn</th>\n",
       "      <th>y_pred_ffnn</th>\n",
       "      <th>ffnn_classifcation_performance_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_true_ffnn  y_pred_ffnn ffnn_classifcation_performance_outcome\n",
       "30         True         True         correctly predicted escalation\n",
       "31        False        False      correctly predicted no escalation\n",
       "32        False         True           wrongly predicted escalation\n",
       "33        False         True           wrongly predicted escalation\n",
       "34        False         True           wrongly predicted escalation\n",
       "35        False         True           wrongly predicted escalation\n",
       "36        False         True           wrongly predicted escalation\n",
       "37        False        False      correctly predicted no escalation\n",
       "38        False        False      correctly predicted no escalation\n",
       "39        False        False      correctly predicted no escalation\n",
       "40        False        False      correctly predicted no escalation\n",
       "41        False        False      correctly predicted no escalation\n",
       "42        False        False      correctly predicted no escalation\n",
       "43        False        False      correctly predicted no escalation\n",
       "44        False        False      correctly predicted no escalation\n",
       "45        False        False      correctly predicted no escalation\n",
       "46        False        False      correctly predicted no escalation\n",
       "47         True        False        wrongly predicted no escalation\n",
       "48        False         True           wrongly predicted escalation\n",
       "49        False         True           wrongly predicted escalation"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ffnn\n",
    "threshold = 0.5\n",
    "df_preds['ffnn_classifcation_performance_outcome'] = None\n",
    "\n",
    "tmp = df_preds['ffnn_classifcation_performance_outcome'].copy()\n",
    "TP_pos_pred_correct = df_preds.y_true_ffnn & (df_preds.y_pred_proba_ffnn>threshold)\n",
    "tmp[TP_pos_pred_correct] = \"correctly predicted escalation\"\n",
    "TN_neg_pred_correct = (~df_preds.y_true_ffnn) & (df_preds.y_pred_proba_ffnn<=threshold)\n",
    "tmp[TN_neg_pred_correct] = \"correctly predicted no escalation\"\n",
    "FP_pos_pred_wrong = (~df_preds.y_true_ffnn) & (df_preds.y_pred_proba_ffnn>threshold)\n",
    "tmp[FP_pos_pred_wrong] = \"wrongly predicted escalation\"\n",
    "FN_neg_pred_wrong = df_preds.y_true_ffnn & (df_preds.y_pred_proba_ffnn<=threshold)\n",
    "tmp[FN_neg_pred_wrong] = \"wrongly predicted no escalation\"\n",
    "\n",
    "df_preds['ffnn_classifcation_performance_outcome'] = tmp\n",
    "df_preds[['y_true_ffnn','y_pred_ffnn','ffnn_classifcation_performance_outcome']][30:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3ca941",
   "metadata": {},
   "source": [
    "# 4. Perform a one sample hypothesis test of the proportion of a specific Prediction Classification \"Correctness\" category for another of these models using all the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b144defe",
   "metadata": {},
   "source": [
    "> $H_0: p=0.25$\n",
    "\n",
    "> $H_a: p \\neq 0.25$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08e2f199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "p_value= np.round(stats.ttest_1samp(df_preds['transformer_classifcation_performance_outcome'] == 'wrongly predicted escalation', keepdims=False, popmean = 0.25)[1], 3)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "581fc5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value= np.round(stats.ttest_1samp(df_preds['transformer_classifcation_performance_outcome'] == 'correctly predicted escalation', keepdims=False, popmean = 0.25)[1], 3)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ccaea76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value= np.round(stats.ttest_1samp(df_preds['transformer_classifcation_performance_outcome'] == 'correctly predicted no escalation', keepdims=False, popmean = 0.25)[1], 3)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbba0daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value= np.round(stats.ttest_1samp(df_preds['transformer_classifcation_performance_outcome'] == 'wrongly predicted no escalation', keepdims=False, popmean = 0.25)[1], 3)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389a8dde",
   "metadata": {},
   "source": [
    "> For transformer predition classification \"correctness\", the p_value calculated is 0.004 and 0.0 which is between strong and very strong evidence against the null hypothesis. Thus, we could reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35624b6f",
   "metadata": {},
   "source": [
    "# 5. Consider the \"Progress Indicators\" data and use \"boolean selection\" with one (or more) of the columns to restrict the data to a subset (of rows) of data and repeat either of the (confidence interval and hypothesis testing) analyses above but this time instead only using this specified subset of countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a16b28c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fsi_x1:_external_intervention</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fsi_category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alert</th>\n",
       "      <td>7.975862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stable</th>\n",
       "      <td>3.772340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sustainable</th>\n",
       "      <td>0.794444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Warning</th>\n",
       "      <td>5.613580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              fsi_x1:_external_intervention\n",
       "fsi_category                               \n",
       "Alert                              7.975862\n",
       "Stable                             3.772340\n",
       "Sustainable                        0.794444\n",
       "Warning                            5.613580"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data wraggling\n",
    "only_2 = df_indicators.loc[:,[\"fsi_category\",\"fsi_x1:_external_intervention\"]]\n",
    "onlyalert = only_2.dropna()\n",
    "onlyalert.groupby(\"fsi_category\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86ed0afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12      , 0.21142857])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bootstap confidence interval\n",
    "no_sample = 10000\n",
    "sample_size = onlyalert.shape[0]\n",
    "np.random.seed(800)\n",
    "bootstrap_mean = []\n",
    "for i in range(no_sample):\n",
    "    bootstrap_sample = np.random.choice((onlyalert['fsi_category'] == \"Alert\"),replace=True,size = sample_size)\n",
    "    bootstrap_mean += [np.mean(bootstrap_sample)]\n",
    "    \n",
    "np.quantile(bootstrap_mean,[0.05,0.95])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0fcdb1",
   "metadata": {},
   "source": [
    "# 6 and 7. Create a two-sample bootstrap confidence interval and perform a hypothesis test comparing the performance of a single model for the data subset created above versus the remaining data not included in that data subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf2e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data wraggling\n",
    "only_2 = df_indicators.loc[:,[\"fsi_category\",\"fsi_x1:_external_intervention\"]]\n",
    "onlyalert = only_2.dropna()\n",
    "onlyalert.groupby(\"fsi_category\").mean()\n",
    "only_2_with4results = only_2.drop(only_2[only_2['fsi_category']== 'Warning'].index)\n",
    "only_2_with3results = only_2_with4results.dropna()\n",
    "only_2_with2results = only_2_with3results .drop(only_2_with3results [only_2_with3results ['fsi_category']== 'Sustainable'].index)\n",
    "only_2_with2results = only_2_with2results.rename(columns={'fsi_x1:_external_intervention': 'external_intervention'})\n",
    "only_2_with2results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa578a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bootstrapping fo\n",
    "np.random.seed(800)\n",
    "no_of_samples = 1000\n",
    "stimulated_value = []\n",
    "bootstrap_intervention_value = only_2_with2results.external_intervention.values.copy()\n",
    "simdata = only_2_with2results.copy()\n",
    "for i in range(no_of_samples):\n",
    "    bootstrap_intervention_value[only_2_with2results.fsi_category == \"Stable\"] = only_2_with2results.external_intervention[only_2_with2results.fsi_category == \"Stable\"].sample(frac=1,replace = True).values\n",
    "    \n",
    "    bootstrap_intervention_value[only_2_with2results.fsi_category == \"Alert\"] = only_2_with2results.external_intervention[only_2_with2results.fsi_category == \"Alert\"].sample(frac=1,replace = True).values\n",
    "    \n",
    "    simdata['external_intervention'] = bootstrap_intervention_value\n",
    "    \n",
    "    simvalue = np.diff(simdata.groupby('fsi_category').mean().values.flatten())[0]\n",
    "    stimulated_value += [simvalue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24fd039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the 90% confidence interval of the stimulated samples\n",
    "np.quantile(stimulated_value,[0.05,0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6633655f",
   "metadata": {},
   "source": [
    "\n",
    "> $H_0: mean of alert is the same as the mean of stable$\n",
    "\n",
    "> $H_a: mean of alert is different from the mean of stable$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de8c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_diff = np.diff(only_2_with2results.groupby('fsi_category').mean().values.flatten())[0]\n",
    "observed_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b916089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#permutation shuffling for hypothesis testing\n",
    "np.random.seed(800)\n",
    "no_of_samples = 1000\n",
    "stimulated_value_underH0 = []\n",
    "\n",
    "simdata = only_2_with2results.copy()\n",
    "for i in range(no_of_samples):\n",
    "    simdata['fsi_category'] = only_2_with2results['fsi_category'] .sample(frac=1,replace = False).values\n",
    "    simvalue = np.diff(simdata.groupby('fsi_category').mean().values.flatten())[0]\n",
    "    stimulated_value_underH0 += [simvalue]\n",
    "    \n",
    "extreme_neg = ((stimulated_value_underH0) <= observed_diff).sum()\n",
    "p_value = extreme_neg / no_of_samples\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e062bd",
   "metadata": {},
   "source": [
    "> In conclusion, the p_value calculated is 0.0 which is smaller than 0.001. This indicates there is very strong evidence against the null hypothesis. Thus, we fail to reject the null hypothesis and we can find that the external_intervention point mean of the alert category in fsi_category is different from that of the stable category. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ff11e0",
   "metadata": {},
   "source": [
    "# 8 and 9. Create a bootstrap confidence interval and a hypothesis test comparing the performance of two the models across all the data on the basis of a \"paired\" sample analysis (by transforming the paired sample into a single difference sample)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20448da8",
   "metadata": {},
   "source": [
    "> $H_0$: mean of life expectancy at birth years_1970 is the same as the mean of life expectancy at birth $years_{2000}$\n",
    "\n",
    "\n",
    "> $H_a$: mean of life expectancy at birth years_1970 is different from the mean of life expectancy at birth $years_{2000}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe8f98e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08 [8.13654997 9.70038523]\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('test_predictions.csv')\n",
    "df_1970 = df_indicators['sowc_demographics__life-expectancy-at-birth-years_1970'].dropna()\n",
    "df_2000 = df_indicators['sowc_demographics__life-expectancy-at-birth-years_2000-0'].dropna()\n",
    "z = df_2000 - df_1970\n",
    "reps = 1000\n",
    "observed = z.mean()\n",
    "null = 0\n",
    "sample_size = 175\n",
    "all_samples = np.zeros(reps)\n",
    "for i in range(reps):\n",
    "    bootstrap = np.random.choice(z, replace=True, size=sample_size)\n",
    "    all_samples[i] = np.mean(bootstrap)  \n",
    "my_bootstrapped_ConfidenceInterval = np.quantile(all_samples,[0.05,0.95])\n",
    "p_value = (abs(bootstrap - null) >= abs(observed - null)).sum()/1000\n",
    "\n",
    "print(p_value, my_bootstrapped_ConfidenceInterval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97382579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=360.0, pvalue=1.9733287695870795e-32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "p_value = stats.wilcoxon(df_2000, df_1970)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3223591e",
   "metadata": {},
   "source": [
    "> As the p value is bewteen 0.1 and 0.05, we have weak evidence against the null hypothesis. Hence, we don't have sufficient evidence to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0b3c63",
   "metadata": {},
   "source": [
    "> $H_0$: mean of indicator for economy is the same as the indicator for public services\n",
    "\n",
    "> $H_a$: mean of indicator for economy is the different from the indicator for public services\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31162570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      10.0\n",
       "1       3.8\n",
       "2       5.0\n",
       "4       8.8\n",
       "6       3.8\n",
       "       ... \n",
       "197     3.8\n",
       "198     9.6\n",
       "199     8.1\n",
       "200     8.8\n",
       "201     4.8\n",
       "Name: fsi_p2:_public_services, Length: 175, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "economy = df_indicators['fsi_e1:_economy'].dropna()\n",
    "public_service = df_indicators['fsi_p2:_public_services'].dropna()\n",
    "public_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e149a9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.158 [0.04451429 0.42002857]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "economy = df_indicators['fsi_e1:_economy'].dropna()\n",
    "public_service = df_indicators['fsi_p2:_public_services'].dropna()\n",
    "z = economy - public_service\n",
    "reps = 1000\n",
    "observed = z.mean()\n",
    "null = 0\n",
    "sample_size = 175\n",
    "all_samples = np.zeros(reps)\n",
    "for i in range(reps):\n",
    "    bootstrap = np.random.choice(z, replace=True, size=sample_size)\n",
    "    all_samples[i] = np.mean(bootstrap)  \n",
    "my_bootstrapped_ConfidenceInterval = np.quantile(all_samples,[0.05,0.95])\n",
    "p_value = (abs(bootstrap - null) >= abs(observed - null)).sum()/1000\n",
    "print(p_value, my_bootstrapped_ConfidenceInterval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479d3b4f",
   "metadata": {},
   "source": [
    "> As the p value is bigger than 0.1, we have no evidence against the null hypothesis. Hence, we don't have evidence to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afbc38c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
